import{_ as p,r as a,o as l,c,a as n,b as s,d as e,w as r,e as t}from"./app-7ac5536a.js";const d={},u=n("h1",{id:"simulation-with-message-passing-interface-mpi",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#simulation-with-message-passing-interface-mpi","aria-hidden":"true"},"#"),s(" Simulation with Message Passing Interface (MPI)")],-1),m=n("p",null,"MPI-based Federated Learning for cross-GPU/CPU servers.",-1),v=n("strong",null,"MPI-based FL simulator",-1),k={href:"https://github.com/FedML-AI/FedML/tree/master/python/examples/simulation/mpi_torch_fedavg_mnist_lr_example",target:"_blank",rel:"noopener noreferrer"},b=t(`<h2 id="one-line-api" tabindex="-1"><a class="header-anchor" href="#one-line-api" aria-hidden="true">#</a> One line API</h2><h3 id="step-1-preparation" tabindex="-1"><a class="header-anchor" href="#step-1-preparation" aria-hidden="true">#</a> Step 1. preparation</h3><p>In this example, we have to complete the operation of step1 in the One line API first, and then proceed to the subsequent operations.</p><p>We use the <code>mpi4py</code> package for the MPI implementation in Python. Here you need to install <code>mpi4py</code> with <code>conda install</code> instead of <code>pip install</code> because pip install will report an error.</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>conda <span class="token function">install</span> mpi4py
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="step-2-setup-parameters" tabindex="-1"><a class="header-anchor" href="#step-2-setup-parameters" aria-hidden="true">#</a> Step 2. setup Parameters</h3><p><code>config/fedml_config.yaml</code> is almost the same as <code>fedml_config.yaml</code> in <strong><u>One line API</u></strong> <strong>step2</strong>, only the backend setting in <code>comm_args</code> is different. Here comm_args.backend is &quot;MPI&quot;, which means the program is running based on an MPI-based FL Simulator.</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token key atrule">comm_args</span><span class="token punctuation">:</span>
  <span class="token key atrule">backend</span><span class="token punctuation">:</span> <span class="token string">&quot;MPI&quot;</span>
  <span class="token key atrule">is_mobile</span><span class="token punctuation">:</span> <span class="token number">0</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="step-3-training" tabindex="-1"><a class="header-anchor" href="#step-3-training" aria-hidden="true">#</a> Step 3. training</h3><p>Now that we have configured all the dependencies, we can quickly implement the training of the federated learning model based on MPI-based FL Simulator on the MNIST dataset with the following line of code.</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># 4 means 4 processes</span>
<span class="token function">bash</span> run_one_line_example.sh <span class="token number">4</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>Note that if you download the code on Windows and upload it to a Linux environment, you will see the following output when the program just starts running.</p><blockquote><p>run_one_line_example.sh: line 2: $&#39; \\r &#39;: command not found</p><p>run_one_line_example.sh: line 4: $&#39;\\r&#39;: command not found</p><p>expr: non-integer argument</p><p>run_one_line_example.sh: line 7: $&#39;\\r&#39;: command not found</p><p>run_one_line_example.sh: line 9: $&#39;\\r&#39;: command not found</p></blockquote><p>The main way to deal with this is to end the program and then run the following command, <code>filename</code> here is <code>run_one_line_example.sh</code></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">sed</span> <span class="token parameter variable">-i</span> <span class="token string">&#39;s/\\r$//&#39;</span> filename
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>When it officially starts running, you can see the real-time output of the program running on the terminal. When the process is finished and you see an output similar to the following, it means that the whole process is running successfully.</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>FedML-Server<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> @device-id-0 - Tue, <span class="token number">26</span> Apr <span class="token number">2022</span> 02:53:22 FedAvgClientManager.py<span class="token punctuation">[</span>line:71<span class="token punctuation">]</span> INFO <span class="token comment">#######training########### round_id = 49</span>
<span class="token punctuation">[</span><span class="token number">2022</span>-04-26 02:53:22,054<span class="token punctuation">]</span> <span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> <span class="token punctuation">[</span>my_model_trainer_classification.py:56:train<span class="token punctuation">]</span> Update Epoch: <span class="token number">0</span> <span class="token punctuation">[</span><span class="token number">10</span>/30 <span class="token punctuation">(</span><span class="token number">33</span>%<span class="token punctuation">)</span><span class="token punctuation">]</span>    Loss: <span class="token number">1.775815</span>
<span class="token punctuation">[</span><span class="token number">2022</span>-04-26 02:53:22,055<span class="token punctuation">]</span> <span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> <span class="token punctuation">[</span>my_model_trainer_classification.py:56:train<span class="token punctuation">]</span> Update Epoch: <span class="token number">0</span> <span class="token punctuation">[</span><span class="token number">20</span>/30 <span class="token punctuation">(</span><span class="token number">67</span>%<span class="token punctuation">)</span><span class="token punctuation">]</span>    Loss: <span class="token number">1.920599</span>
<span class="token punctuation">[</span><span class="token number">2022</span>-04-26 02:53:22,055<span class="token punctuation">]</span> <span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> <span class="token punctuation">[</span>my_model_trainer_classification.py:56:train<span class="token punctuation">]</span> Update Epoch: <span class="token number">0</span> <span class="token punctuation">[</span><span class="token number">30</span>/30 <span class="token punctuation">(</span><span class="token number">100</span>%<span class="token punctuation">)</span><span class="token punctuation">]</span>   Loss: <span class="token number">1.839799</span>
<span class="token punctuation">[</span><span class="token number">2022</span>-04-26 02:53:22,055<span class="token punctuation">]</span> <span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> <span class="token punctuation">[</span>my_model_trainer_classification.py:63:train<span class="token punctuation">]</span> Client Index <span class="token operator">=</span> <span class="token number">3</span> Epoch: <span class="token number">0</span>        Loss: <span class="token number">1.845405</span>
FedML-Server<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> @device-id-0 - Tue, <span class="token number">26</span> Apr <span class="token number">2022</span> 02:53:22 client_manager.py<span class="token punctuation">[</span>line:104<span class="token punctuation">]</span> INFO Sending message <span class="token punctuation">(</span>type <span class="token number">3</span><span class="token punctuation">)</span> to server
FedML-Server<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> @device-id-0 - Tue, <span class="token number">26</span> Apr <span class="token number">2022</span> 02:53:22 client_manager.py<span class="token punctuation">[</span>line:118<span class="token punctuation">]</span> INFO __finish client
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank <span class="token number">4</span> <span class="token keyword">in</span> communicator MPI_COMM_WORLD
with errorcode <span class="token number">0</span>.

NOTE: invoking MPI_ABORT causes Open MPI to <span class="token function">kill</span> all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Let&#39;s have a look at the <code>run_one_line_example.sh</code></p><ul><li><p>When we run the above command, 4 will be assigned to the parameter <code>WORKER_NUM</code>, representing 4 client processes.</p></li><li><p>Executing <code>echo $PROCESS_NUM</code> will output 5 on the terminal, representing the total number of processes is 5 (including server).</p></li><li><p><code>hostname &gt; mpi_host_file</code></p></li><li><p><code>$(which mpirun) -np $PROCESS_NUM \\</code><code>-hostfile mpi_host_file --oversubscribe \\</code><code>python torch_fedavg_mnist_lr_one_line_example.py --cf config/fedml_config.yaml</code> This line of code mpirun will run the program using the mpi method and specify the parameter file with <code>-np $PROCESS_NUM</code> specifies the total number of processes in the program, <code>--cf config/fedml_config.yaml</code>, <code>hostname &gt; mpi_host_file</code> write the hostname to the mpi_host_file fileand <code>-hostfile mpi_host_file</code> specifies the host file of the mpi</p></li></ul><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token shebang important">#!/usr/bin/env bash</span>

<span class="token assign-left variable">WORKER_NUM</span><span class="token operator">=</span><span class="token variable">$1</span>

<span class="token assign-left variable">PROCESS_NUM</span><span class="token operator">=</span><span class="token variable"><span class="token variable">\`</span><span class="token function">expr</span> $WORKER_NUM + <span class="token number">1</span><span class="token variable">\`</span></span>
<span class="token builtin class-name">echo</span> <span class="token variable">$PROCESS_NUM</span>

<span class="token function">hostname</span> <span class="token operator">&gt;</span> mpi_host_file

<span class="token variable"><span class="token variable">$(</span><span class="token function">which</span> mpirun<span class="token variable">)</span></span> <span class="token parameter variable">-np</span> <span class="token variable">$PROCESS_NUM</span> <span class="token punctuation">\\</span>
<span class="token parameter variable">-hostfile</span> mpi_host_file <span class="token parameter variable">--oversubscribe</span> <span class="token punctuation">\\</span>
python torch_fedavg_mnist_lr_one_line_example.py <span class="token parameter variable">--cf</span> config/fedml_config.yaml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The code for <code>torch_fedavg_mnist_lr_one_line_example.py</code> is shown below:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> fedml


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span>
    fedml<span class="token punctuation">.</span>run_simulation<span class="token punctuation">(</span>backend<span class="token operator">=</span><span class="token string">&quot;MPI&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="step-4-view-the-results" tabindex="-1"><a class="header-anchor" href="#step-4-view-the-results" aria-hidden="true">#</a> Step 4. view the results</h3><p>You can view the output log files in the <code>/log</code> directory under the current directory.</p><h2 id="step-by-step-api" tabindex="-1"><a class="header-anchor" href="#step-by-step-api" aria-hidden="true">#</a> Step by step API</h2><p>First, we should also complete the step1 and step2 operations in the <strong>one-line example</strong> and quickly implement the federation learning model training on the MNIST dataset with the following line of code for the MPI-based FL Simulator.</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">sh</span> run_step_by_step_example.sh <span class="token number">4</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>The code of <code>run_step_by_step_example.sh</code> is as follows, which is generally the same as <code>run_one_line_example.sh</code> in this section of the <strong>One line API</strong></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token shebang important">#!/usr/bin/env bash</span>

<span class="token assign-left variable">WORKER_NUM</span><span class="token operator">=</span><span class="token variable">$1</span>

<span class="token assign-left variable">PROCESS_NUM</span><span class="token operator">=</span><span class="token variable"><span class="token variable">\`</span><span class="token function">expr</span> $WORKER_NUM + <span class="token number">1</span><span class="token variable">\`</span></span>
<span class="token builtin class-name">echo</span> <span class="token variable">$PROCESS_NUM</span>

<span class="token function">hostname</span> <span class="token operator">&gt;</span> mpi_host_file

<span class="token variable"><span class="token variable">$(</span><span class="token function">which</span> mpirun<span class="token variable">)</span></span> <span class="token parameter variable">-np</span> <span class="token variable">$PROCESS_NUM</span> <span class="token punctuation">\\</span>
<span class="token parameter variable">-hostfile</span> mpi_host_file <span class="token parameter variable">--oversubscribe</span> <span class="token punctuation">\\</span>
python torch_fedavg_mnist_lr_step_by_step_example.py <span class="token parameter variable">--cf</span> config/fedml_config.yaml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The code of <code>torch_fedavg_mnist_lr_step_by_step_example.py</code> is shown below. We can see that the code follows the steps of the <strong>Step by step API</strong> in <strong>Example: Simulate FL using a single process</strong>.</p><p>The difference is that <code>simulator = SimulatorMPI(args, device, dataset, model)</code> is used to initialize the model object, which means that MPI-based FL Simulator is used here for training</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> fedml
<span class="token keyword">from</span> fedml<span class="token punctuation">.</span>simulation <span class="token keyword">import</span> SimulatorMPI

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span>
    <span class="token comment"># init FedML framework</span>
    args <span class="token operator">=</span> fedml<span class="token punctuation">.</span>init<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># init device</span>
    device <span class="token operator">=</span> fedml<span class="token punctuation">.</span>device<span class="token punctuation">.</span>get_device<span class="token punctuation">(</span>args<span class="token punctuation">)</span>

    <span class="token comment"># load data</span>
    dataset<span class="token punctuation">,</span> output_dim <span class="token operator">=</span> fedml<span class="token punctuation">.</span>data<span class="token punctuation">.</span>load<span class="token punctuation">(</span>args<span class="token punctuation">)</span>

    <span class="token comment"># load model</span>
    model <span class="token operator">=</span> fedml<span class="token punctuation">.</span>model<span class="token punctuation">.</span>create<span class="token punctuation">(</span>args<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>

    <span class="token comment"># start training</span>
    simulator <span class="token operator">=</span> SimulatorMPI<span class="token punctuation">(</span>args<span class="token punctuation">,</span> device<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> model<span class="token punctuation">)</span>
    simulator<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="custom-data-and-model" tabindex="-1"><a class="header-anchor" href="#custom-data-and-model" aria-hidden="true">#</a> Custom data and model</h2>`,33),h=n("strong",null,"custom data and mode",-1),_=n("strong",null,[n("u",null,"Simulate FL using a single process")],-1),g=t(`<p>In this section we will present how to <strong>customize the dataset and model</strong> using FedML based on the <code>Step by step example</code> and implement a stand-alone simulated version of the FedAvg algorithm.</p><p>First we still need to complete the first two cases step1 and step2, and then we can quickly implement the federation learning model training on the MNIST dataset with the following line of code for stand-alone simulation:</p><div class="language-Nginx line-numbers-mode" data-ext="Nginx"><pre class="language-Nginx"><code>python torch_fedavg_mnist_lr_custum_data_and_model_example.py --cf fedml_config.yaml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>The <code>torch_fedavg_mnist_lr_custum_data_and_model_example.py</code> defines the</p><p><code>load_data(args)</code> function for loading the dataset and related information, and the</p><p><code>LogisticRegression(torch.nn. Module)</code> class defines the LogisticRegression model. The specific code is as follows:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">load_data</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    download_mnist<span class="token punctuation">(</span>args<span class="token punctuation">.</span>data_cache_dir<span class="token punctuation">)</span>
    fedml<span class="token punctuation">.</span>logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">&quot;load_data. dataset_name = %s&quot;</span> <span class="token operator">%</span> args<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>

    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Please read through the data loader at to see how to customize the dataset for FedML framework.
    &quot;&quot;&quot;</span>
    <span class="token punctuation">(</span>
        client_num<span class="token punctuation">,</span>
        train_data_num<span class="token punctuation">,</span>
        test_data_num<span class="token punctuation">,</span>
        train_data_global<span class="token punctuation">,</span>
        test_data_global<span class="token punctuation">,</span>
        train_data_local_num_dict<span class="token punctuation">,</span>
        train_data_local_dict<span class="token punctuation">,</span>
        test_data_local_dict<span class="token punctuation">,</span>
        class_num<span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">=</span> load_partition_data_mnist<span class="token punctuation">(</span>
        args<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>
        train_path<span class="token operator">=</span>args<span class="token punctuation">.</span>data_cache_dir <span class="token operator">+</span> <span class="token string">&quot;MNIST/train&quot;</span><span class="token punctuation">,</span>
        test_path<span class="token operator">=</span>args<span class="token punctuation">.</span>data_cache_dir <span class="token operator">+</span> <span class="token string">&quot;MNIST/test&quot;</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    For shallow NN or linear models, 
    we uniformly sample a fraction of clients each round (as the original FedAvg paper)
    &quot;&quot;&quot;</span>
    args<span class="token punctuation">.</span>client_num_in_total <span class="token operator">=</span> client_num
    dataset <span class="token operator">=</span> <span class="token punctuation">[</span>
        train_data_num<span class="token punctuation">,</span>
        test_data_num<span class="token punctuation">,</span>
        train_data_global<span class="token punctuation">,</span>
        test_data_global<span class="token punctuation">,</span>
        train_data_local_num_dict<span class="token punctuation">,</span>
        train_data_local_dict<span class="token punctuation">,</span>
        test_data_local_dict<span class="token punctuation">,</span>
        class_num<span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
    <span class="token keyword">return</span> dataset<span class="token punctuation">,</span> class_num

<span class="token keyword">class</span> <span class="token class-name">LogisticRegression</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LogisticRegression<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> outputs
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>torch_fedavg_mnist_lr_custum_data_and_model_example.py</code> is similar to <code>torch_fedavg_mnist_lr_step_by_step_example.py</code>, the code includes the same parts, though <code>torch_fedavg_mnist_lr_custum_data_and_model_example.py</code> loads the dataset and the model definition part using custom function and class. The code for the training process is shown below:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span>
    <span class="token comment"># init FedML framework</span>
    args <span class="token operator">=</span> fedml<span class="token punctuation">.</span>init<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># init device</span>
    device <span class="token operator">=</span> fedml<span class="token punctuation">.</span>device<span class="token punctuation">.</span>get_device<span class="token punctuation">(</span>args<span class="token punctuation">)</span>

    <span class="token comment"># load data</span>
    dataset<span class="token punctuation">,</span> output_dim <span class="token operator">=</span> load_data<span class="token punctuation">(</span>args<span class="token punctuation">)</span>

    <span class="token comment"># load model (the size of MNIST image is 28 x 28)</span>
    model <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span><span class="token number">28</span> <span class="token operator">*</span> <span class="token number">28</span><span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>

    <span class="token comment"># start training</span>
    simulator <span class="token operator">=</span> SimulatorMPI<span class="token punctuation">(</span>args<span class="token punctuation">,</span> device<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> model<span class="token punctuation">)</span>
    simulator<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="develop-new-algorithms" tabindex="-1"><a class="header-anchor" href="#develop-new-algorithms" aria-hidden="true">#</a> Develop new algorithms</h2><h3 id="base-framework" tabindex="-1"><a class="header-anchor" href="#base-framework" aria-hidden="true">#</a> Base framework</h3><p><code>python/examples/simulation/mpi_base_framework_example</code></p><p>This is a base framework used to develop new algorithm. You can copy this directory and modify directly. The basic message flow is workable. What you need to do is designing the message flow and defining the payload of each message.</p><p>As a research library, our philosophy is to give flexibility to users and avoid over-designed software patterns.</p><p>Run the example:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">sh</span> run.sh <span class="token number">4</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><code>run.sh</code></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token shebang important">#!/usr/bin/env bash</span>

<span class="token assign-left variable">WORKER_NUM</span><span class="token operator">=</span><span class="token variable">$1</span>

<span class="token assign-left variable">PROCESS_NUM</span><span class="token operator">=</span><span class="token variable"><span class="token variable">\`</span><span class="token function">expr</span> $WORKER_NUM + <span class="token number">1</span><span class="token variable">\`</span></span>
<span class="token builtin class-name">echo</span> <span class="token variable">$PROCESS_NUM</span>

<span class="token function">hostname</span> <span class="token operator">&gt;</span> mpi_host_file

<span class="token variable"><span class="token variable">$(</span><span class="token function">which</span> mpirun<span class="token variable">)</span></span> <span class="token parameter variable">-np</span> <span class="token variable">$PROCESS_NUM</span> <span class="token punctuation">\\</span>
<span class="token parameter variable">-hostfile</span> mpi_host_file <span class="token parameter variable">--oversubscribe</span> <span class="token punctuation">\\</span>
python mpi_base_framework_example.py <span class="token parameter variable">--cf</span> config/fedml_config.yaml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>mpi_base_framework_example.py</code></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> fedml
<span class="token keyword">from</span> fedml <span class="token keyword">import</span> SimulatorMPI

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span>
    <span class="token comment"># init FedML framework</span>
    args <span class="token operator">=</span> fedml<span class="token punctuation">.</span>init<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># start training</span>
    simulator <span class="token operator">=</span> SimulatorMPI<span class="token punctuation">(</span>args<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
    simulator<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>You can customize <strong>device, dataset, model</strong> in this base framework.</p><h3 id="decentralized-framework" tabindex="-1"><a class="header-anchor" href="#decentralized-framework" aria-hidden="true">#</a> Decentralized framework</h3><p><code>python/examples/simulation/mpi_decentralized_fl_example</code></p><p>This is a decentralized framework used to develop new algorithm. You can copy this directory and modify directly. The basic message flow is workable. What you need to do is designing the message flow and defining the payload of each message.</p><p>As a research library, our philosophy is giving flexibility to users and avoid overdesigned software pattern.</p><p>Run the example:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">sh</span> run.sh <span class="token number">4</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><code>run.sh</code></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token shebang important">#!/usr/bin/env bash</span>

<span class="token assign-left variable">WORKER_NUM</span><span class="token operator">=</span><span class="token variable">$1</span>

<span class="token assign-left variable">PROCESS_NUM</span><span class="token operator">=</span><span class="token variable"><span class="token variable">\`</span><span class="token function">expr</span> $WORKER_NUM + <span class="token number">1</span><span class="token variable">\`</span></span>
<span class="token builtin class-name">echo</span> <span class="token variable">$PROCESS_NUM</span>

<span class="token function">hostname</span> <span class="token operator">&gt;</span> mpi_host_file

<span class="token variable"><span class="token variable">$(</span><span class="token function">which</span> mpirun<span class="token variable">)</span></span> <span class="token parameter variable">-np</span> <span class="token variable">$PROCESS_NUM</span> <span class="token punctuation">\\</span>
<span class="token parameter variable">-hostfile</span> mpi_host_file <span class="token parameter variable">--oversubscribe</span> <span class="token punctuation">\\</span>
python mpi_decentralized_fl_example.py <span class="token parameter variable">--cf</span> config/fedml_config.yaml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>mpi_decentralized_fl_example.py</code></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> fedml
<span class="token keyword">from</span> fedml <span class="token keyword">import</span> SimulatorMPI

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span>
    <span class="token comment"># init FedML framework</span>
    args <span class="token operator">=</span> fedml<span class="token punctuation">.</span>init<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># start training</span>
    simulator <span class="token operator">=</span> SimulatorMPI<span class="token punctuation">(</span>args<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
    simulator<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>You can customize <strong>device, dataset, model</strong> in this base framework.</p>`,32);function f(y,w){const i=a("ExternalLinkIcon"),o=a("RouterLink");return l(),c("div",null,[u,m,n("p",null,[s("In this example, we will present how to apply the standalone simulation of FedML in the MINIST image classification using an "),v,s(". The complete code is available at "),n("a",k,[s("https://github.com/FedML-AI/FedML/tree/master/python/examples/simulation/mpi_torch_fedavg_mnist_lr_example"),e(i)]),s(".")]),b,n("p",null,[s("The operation of this part is similar to the "),h,s("l part in example "),e(o,{to:"/simulation/examples/sp_fedavg_mnist_lr_example.html"},{default:r(()=>[_]),_:1}),s(" .")]),g])}const M=p(d,[["render",f],["__file","mpi_torch_fedavg_mnist_lr_example.html.vue"]]);export{M as default};
