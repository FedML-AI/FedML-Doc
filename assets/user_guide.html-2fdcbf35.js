import{_ as r,a as s}from"./MLOps_workflow-c6196ca5.js";import{_ as i}from"./cross-silo-hi-2a73b75b.js";import{_ as n,r as d,o as l,c,a as e,b as t,d as o,e as h}from"./app-7ac5536a.js";const u={},p=h('<h1 id="fedml-octopus-user-guide" tabindex="-1"><a class="header-anchor" href="#fedml-octopus-user-guide" aria-hidden="true">#</a> FedML Octopus User Guide</h1><img src="'+r+'" alt="octopus" style="width:650px;"><p>FedML Octopus is the industrial grade platform of cross-silo federated learning for cross-organization/account training. It provides the federated learning service and edge AI SDK for developers or companies to conduct open collaboration from anywhere at any scale in a secure manner.</p><h2 id="seamlessly-transplant-the-simulation-code-parrot-to-real-world-cross-device-fl-octopus" tabindex="-1"><a class="header-anchor" href="#seamlessly-transplant-the-simulation-code-parrot-to-real-world-cross-device-fl-octopus" aria-hidden="true">#</a> Seamlessly transplant the simulation code (Parrot) to real-world cross-device FL (Octopus)</h2><p>The most advanced and easy-to-use feature at FedML Octopus is the MLOps support. Researchers and engineers do not need to maintain the complex geo-distributed GPU/CPU cluster. Essentially, Our MLOps can seamlessly migrate the local development to the real-world edge-cloud deployment without code changes. A detailed workflow is shown as below.</p><p><img src="'+s+'" alt="image"></p>',6),m={href:"https://doc.fedml.ai/mlops/user_guide.html",target:"_blank",rel:"noopener noreferrer"},f=e("h2",{id:"heterogeneous-hierarchical-federated-learning-supporting-local-allreduce-based-distributed-training",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#heterogeneous-hierarchical-federated-learning-supporting-local-allreduce-based-distributed-training","aria-hidden":"true"},"#"),t(" Heterogeneous hierarchical federated learning: supporting local AllReduce-based distributed training")],-1),g=e("p",null,"System heterogeneity is one of the key challenges in practical federated learning. All existing open federated learning frameworks do not consider the practical scenario where different data silos may have different numbers of GPUs or even multiple nodes (where each node has multiple GPUs), as shown as the figure below.",-1),_=e("img",{src:i,alt:"parrot",style:{width:"100%"}},null,-1),b=e("p",null,"FedML Octopus addresses this challenge by enabling a distributed training paradigm (PyTorch DDP, distributed data parallel) to run inside each data-silo, and further orchestrate different silos with asynchronous or synchronous federated optimization method. As a result, FedML Octopus can support this scenario in a flexible, secure, and efficient manner. FedML MLOps platform also simplifies its real-world deployment.",-1),y={href:"https://doc.fedml.ai/cross-silo/examples.html",target:"_blank",rel:"noopener noreferrer"},w=e("h2",{id:"diverse-communication-backends-for-different-cross-silo-scenario",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#diverse-communication-backends-for-different-cross-silo-scenario","aria-hidden":"true"},"#"),t(" Diverse Communication Backends for different cross-silo scenario")],-1),v=e("p",null,[t("FedML Octopus supports "),e("a",{href:"(https://github.com/FedML-AI/FedML/tree/master/python/fedml/core/distributed/communication)"},"diverse communication backends"),t(", including MQTT+S3, MQTT, PyTorch RPC, gRPC, and MPI. These communication backends meet the different demands for high-performance, low latency, and robust connection.")],-1);function x(L,M){const a=d("ExternalLinkIcon");return l(),c("div",null,[p,e("p",null,[t("You can also read "),e("a",m,[t("the tutorial"),o(a)]),t(" to see how easy it is to simplify the real-world deployment (including an video tutorial).")]),f,g,_,b,e("p",null,[t("Please read the detailed "),e("a",y,[t("examples and tutorial"),o(a)]),t(" for details.")]),w,v])}const F=n(u,[["render",x],["__file","user_guide.html.vue"]]);export{F as default};
